> :exclamation: D√™ um feedback para esse documento no rodap√©.[^1]
![](https://eni.bb.com.br/eni1/matomo.php?idsite=469&amp;rec=1&amp;url=https://fontes.intranet.bb.com.br/dev/publico/roteiros/-/blob/master/kubernetes/resource-quota.md&amp;action_name=kubernetes/resource-quota.md)

# Resource quota e resource limits no k8s

## Objetivo

Este roteiro visa detalhar como funciona o provisionamento de recurso computacional dentro do contexto de aplica√ß√µes da DevCloud.

## Sum√°rio

[[_TOC_]]

## Resource quota

ResourceQuota √© um tipo de objeto do Kubernetes usado para definir limites de uso de recurso computacional em um determinado contexto. Na DevCloud, a sua configura√ß√£o por parte do time de infraestrutura previne que um namespace mal configurado expanda seu consumo de recursos indefinidamente e impacte outras aplica√ß√µes.

## Resource limit

Resouce limits s√£o pol√≠ticas aplicadas por recurso, como pods e conteineres.

## Consultando cotas e limites

A sa√≠da do comando `kubectl describe namespace <meu-namespace>` inclui Resource quota do namespace e os resource limits aplic√°veis aos pods e conteineres daquele namespace.

Por padr√£o, √© algo parecido com isso:

```
Resource Quotas
  Name:                             wlt-carteiras-digitais
  Resource                          Used    Hard
  --------                          ---     ---
  count/configmaps                  2       10
  count/cronjobs.batch              0       5
  count/deployments.apps            1       6
  count/dnsingresses.psc.bb.com.br  1       2
  count/ingresses                   0       5
  count/jobs.batch                  0       10
  count/persistentvolumeclaims      0       2
  count/pods                        2       20
  count/secrets                     8       20
  count/services                    1       12
  count/services.loadbalancers      0       0
  count/services.nodeports          0       0
  count/statefulsets.apps           0       0
  limits.ephemeral-storage          0       10Gi
  limits.memory                     1500Mi  20Gi
  requests.cpu                      20m     5
  requests.ephemeral-storage        0       10Gi
  requests.memory                   1000Mi  10Gi
  requests.storage                  0       5Gi

Resource Limits
 Type       Resource  Min  Max  Default Request  Default Limit  Max Limit/Request Ratio
 ----       --------  ---  ---  ---------------  -------------  -----------------------
 Container  memory    -    8Gi  8Gi              8Gi            -
 Pod        memory    -    8Gi  -                -              -
```

Na se√ß√£o de "Resource Quotas", √© poss√≠vel ver quanto o namespace usa (na coluna Used) e qual √© o limite (na coluna Hard). Note que as cotas incluem n√£o somente mem√≥ria e cpu, mas tamb√©m quantidade de certos tipos de recursos. Na sa√≠da de exemplo, temos que s√≥ √© permitida a declara√ß√£o de dois dnsingress no namespace.

Na se√ß√£o de "Resource limits", temos limita√ß√£o de mem√≥ria por pod e por conteiner. Isso significa que mesmo que o limite de mem√≥ria desse namespace seja 20Gi, n√£o √© poss√≠vel subir um pod que exija mais de 8Gi de limite de mem√≥ria.

## Entendendo o uso do namespace

A quantidade de recursos usada pelo namespace inclui todos os objetos ativos simultaneamente. Isso quer dizer que, por exemplo, para namespaces que utilizam o curi√≥, o consumo de recursos deve ser somado entre as se√ß√µes da aplica√ß√£o e do curi√≥.

## Resource quota no deploy

Um problema comum, especialmente em produ√ß√£o, √© ter o Resource Quota impactando no deploy, impedindo-o na pr√°tica.

Suponha um namespace que tenha 10 unidades de CPU de limite no Resource Quota. O time de desenvolvimento, por temer alta carga no ambiente de produ√ß√£o, resolve calcular quantos pods vai utilizar. Soma os limites de CPU da aplica√ß√£o (por exemplo, 500m) com os do curi√≥ (500m tamb√©m nesse exemplo), e ajusta o `replicaCount` ou o n√∫mero m√°ximo de r√©plicas do HPA para 10. Parece uma conta simples, (500m + 500m)x10 vai caber nas 10 unidades de CPU da cota. Ao fazer o ajuste, vai funcionar corretamente.

O problema √© que o pr√≥ximo deploy n√£o vai acontecer corretamente. No momento em que algo for atualizado no values, como a vers√£o da aplica√ß√£o ou uma nova opera√ß√£o consumida no curi√≥, o Argo vai detectar as mudan√ßas e iniciar a cria√ß√£o dos novos pods em um novo ReplicaSet. E a√≠ est√° o problema. Utilizando a estrat√©gia padr√£o de `RollingUpdate`, o k8s vai tentar criar pods da nova vers√£o antes de tirar de opera√ß√£o pods antigos, e esses pods novos n√£o ter√£o mais disponibilidade de cota para serem criados. O deploy fica "congelado" com erro no `ReplicaSet`.

-----

[^1]: [üëçüëé](http://feedback.dev.intranet.bb.com.br/?origem=roteiros&url_origem=fontes.intranet.bb.com.br/dev/publico/roteiros/-/blob/master/kubernetes/resource-quota.md&internalidade=kubernetes/resource-quota)